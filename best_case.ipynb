{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from preprocessing.preprocessing import load_data\n",
    "from sklearn.model_selection import KFold\n",
    "from model.meta_learner import r2_score_oos, convert_to_onnx\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_in_cv(df, target_name, input_list):\n",
    "    \"\"\"\n",
    "    Train a LightGBM regression model using cross-validation and evaluate its performance on various metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the dataset.\n",
    "    - target_name (str): The name of the target variable to predict.\n",
    "    - input_list (list): A list containing different metric lists for storing evaluation results.\n",
    "\n",
    "    Returns:\n",
    "    List of lists containing evaluation metrics for each fold and the respective subsets of the test data:\n",
    "    [mse_list, r2_list, mae_list, mse2_list, mse3_list, mse10_list, mae2_list, mae3_list, mae10_list]\n",
    "\n",
    "    Notes:\n",
    "    - The function uses LightGBM's 'gbdt' boosting type for regression.\n",
    "    - The model is trained on each fold's training data and evaluated on the corresponding test data.\n",
    "    - Subsets of the test data are defined based on target value thresholds and GPS speed conditions.\n",
    "    \"\"\"\n",
    "    #extract input list\n",
    "    mse_list = input_list[0]\n",
    "    r2_list = input_list[1]\n",
    "    mae_list = input_list[2]\n",
    "    mse2_list = input_list[3]\n",
    "    mse3_list = input_list[4]\n",
    "    mse10_list = input_list[5]\n",
    "    mae2_list = input_list[6]\n",
    "    mae3_list = input_list[7]\n",
    "    mae10_list = input_list[8]\n",
    "\n",
    "    unique_ids = df['driveID'].unique()\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for i, (all_train_ids, test_ids) in enumerate(kfold.split(unique_ids)):\n",
    "        # get selected driveIDs and split data\n",
    "        df_train = df[df['driveID'].isin(all_train_ids)].sample(frac=1, random_state=42)\n",
    "        df_test = df[df['driveID'].isin(test_ids)]\n",
    "        y_train = df_train[target_name]\n",
    "        y_test = df_test[target_name]\n",
    "\n",
    "        # drop irrelevant data\n",
    "        irrelevant_feature_list = [target_name, \"driveID\", \"target_forward\", \"timestamp_utc\", \"groupID\", \"osmID\"]\n",
    "        irrelevant_feature_list.extend(list(df.columns[df.columns.str.contains('target_')]))\n",
    "        X_train = df_train.drop(irrelevant_feature_list, axis=1)\n",
    "        X_test = df_test.drop(irrelevant_feature_list, axis=1)\n",
    "\n",
    "        # train model\n",
    "        model = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        model.fit(X_train, y_train)\n",
    "        convert_to_onnx(model, \"best_case\", target_name)\n",
    "        # create different subsets for acceleration and speed thresholds\n",
    "        df_2 = y_test[abs(y_test) > 2].copy()\n",
    "        df_3 = y_test[abs(y_test) > 3].copy()\n",
    "        threshold_kmh = 10\n",
    "        mask = np.array(df_test['gps_speed'] > (threshold_kmh / 3.6))\n",
    "        df_4 = y_test[mask].copy()\n",
    "\n",
    "        # run model for validation data\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_2 = model.predict(X_test.loc[df_2.index.values.tolist()])\n",
    "        y_pred_3 = model.predict(X_test.loc[df_3.index.values.tolist()])\n",
    "        y_pred_4 = model.predict(X_test.loc[df_4.index.values.tolist()])\n",
    "\n",
    "        # store results\n",
    "        mse_list.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "        r2_list.append(r2_score_oos(y_test, y_pred, df_train[target_name].mean()))\n",
    "        mae_list.append(metrics.mean_absolute_error(y_test, y_pred))\n",
    "        mse2_list.append(metrics.mean_squared_error(df_2, y_pred_2))\n",
    "        mse3_list.append(metrics.mean_squared_error(df_3, y_pred_3))\n",
    "        mse10_list.append(metrics.mean_squared_error(df_4, y_pred_4))\n",
    "        mae2_list.append(metrics.mean_absolute_error(df_2, y_pred_2))\n",
    "        mae3_list.append(metrics.mean_absolute_error(df_3, y_pred_3))\n",
    "        mae10_list.append(metrics.mean_absolute_error(df_4, y_pred_4))\n",
    "\n",
    "    return [mse_list, r2_list, mae_list, mse2_list, mse3_list, mse10_list, mae2_list, mae3_list, mae10_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_with_train_test_split(df):\n",
    "    \"\"\"\n",
    "    Train a LightGBM regression model using the train-test split approach and convert it to ONNX format.\n",
    "\n",
    "    This function trains a LightGBM regression model using the train-test split approach, where the dataset is\n",
    "    divided into training and testing subsets. The model is trained on the training subset and evaluated on the\n",
    "    testing subset. After training, the function converts the trained model to ONNX format for interoperability.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Notes:\n",
    "    - The target variable for regression is assumed to be \"target_forward\".\n",
    "    - Irrelevant features, such as target-related columns and metadata, are removed from the input DataFrame.\n",
    "    - The model is trained using LightGBM's 'gbdt' boosting type with the 'regression' objective.\n",
    "    - The trained model is then converted to ONNX format using the 'convert_to_onnx' function.\n",
    "    \"\"\"\n",
    "    target_name = \"target_forward\"\n",
    "\n",
    "    # split data\n",
    "    y = df[target_name]\n",
    "    irrelevant_feature_list = [target_name, \"driveID\", \"timestamp_utc\", \"groupID\", \"osmID\"]\n",
    "    irrelevant_feature_list.extend(list(df.columns[df.columns.str.contains('target_')]))\n",
    "    X = df.drop(irrelevant_feature_list, axis=1)\n",
    "\n",
    "    # convert all features to float for onnx\n",
    "    X = X.astype(\"float32\")\n",
    "\n",
    "    # train model\n",
    "    model = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # convert to onnx\n",
    "    #convert_to_onnx(model, \"best_case\", target_name, len(X.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load in Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = load_data(save_dir = '/home/stud03/data_science_challenge/data/V4', dropna=False, drop_accel_invalid=True, drop_gyro_invalid=True,drop_gps_invalid=True)\n",
    "df = df.dropna()\n",
    "# The next line drops out the GPS positions, comment it out if they should be relevant in training (Step 2)\n",
    "df = df.drop(columns=['gps_lat', 'gps_long', 'gps_lat_m', 'gps_long_m'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "# Count the number of entries for each driveID\n",
    "drive_counts = df['driveID'].value_counts()\n",
    "\n",
    "# Get the driveIDs with at least 5 entries\n",
    "valid_drive_ids = drive_counts[drive_counts >= 10].index\n",
    "\n",
    "# Filter the DataFrame based on the valid driveIDs\n",
    "df = df[df['driveID'].isin(valid_drive_ids)]\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train 1 LightGBM Model with all features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_name = 'target_left'\n",
    "\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "mae_list = []\n",
    "mse2_list = []\n",
    "mse3_list =[]\n",
    "mse10_list = []\n",
    "mae2_list = []\n",
    "mae3_list = []\n",
    "mae10_list = []\n",
    "\n",
    "input_list = [mse_list, r2_list, mae_list, mse2_list, mse3_list, mse10_list, mae2_list, mae3_list, mae10_list]\n",
    "\n",
    "result_list = train_in_cv(df, target_name,input_list)\n",
    "\n",
    "\n",
    "print(\"MSE: \", np.array(result_list[0]).mean())\n",
    "print(\"R^2: \",np.array(result_list[1]).mean())\n",
    "print(\"MAE: \",np.array(result_list[2]).mean())\n",
    "print(\"MSE a > 2: \",np.array(result_list[3]).mean())\n",
    "print(\"MSE a > 3: \",np.array(result_list[4]).mean())\n",
    "print(\"MSE s > 10: \",np.array(result_list[5]).mean())\n",
    "print(\"MAE a > 2: \",np.array(result_list[6]).mean())\n",
    "print(\"MAE a > 3: \",np.array(result_list[7]).mean())\n",
    "print(\"MAE s > 10: \",np.array(result_list[8]).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train 1 LightGBM Model per GroupID with all features\n",
    "## The result is the mean of all models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_name = 'target_forward'\n",
    "\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "mae_list = []\n",
    "mse2_list = []\n",
    "mse3_list =[]\n",
    "mse10_list = []\n",
    "mae2_list = []\n",
    "mae3_list = []\n",
    "mae10_list = []\n",
    "\n",
    "result_list = [mse_list, r2_list, mae_list, mse2_list, mse3_list, mse10_list, mae2_list, mae3_list, mae10_list]\n",
    "\n",
    "for i in range(1,10):\n",
    "    sub_df = df[df[\"groupID\"] == i]\n",
    "    result_list = train_in_cv(df, target_name, result_list)\n",
    "\n",
    "print(\"MSE: \", np.array(result_list[0]).mean())\n",
    "print(\"R^2: \",np.array(result_list[1]).mean())\n",
    "print(\"MAE: \",np.array(result_list[2]).mean())\n",
    "print(\"MSE a > 2: \",np.array(result_list[3]).mean())\n",
    "print(\"MSE a > 3: \",np.array(result_list[4]).mean())\n",
    "print(\"MSE s > 10: \",np.array(result_list[5]).mean())\n",
    "print(\"MAE a > 2: \",np.array(result_list[6]).mean())\n",
    "print(\"MAE a > 3: \",np.array(result_list[7]).mean())\n",
    "print(\"MAE s > 10: \",np.array(result_list[8]).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train with normal Train-Test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_with_train_test_split(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}